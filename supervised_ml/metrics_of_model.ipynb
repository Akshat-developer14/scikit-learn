{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d8afe0",
   "metadata": {},
   "source": [
    "# Metrics of Model in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec244c",
   "metadata": {},
   "source": [
    "## We can use metrics to evaluate the performance of our model.\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "    - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef87d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f353bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True answers - what actually happened\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "# Predicted answers - what the model predicted\n",
    "y_predicted = [1, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e848e12",
   "metadata": {},
   "source": [
    "- Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f197a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4eb37",
   "metadata": {},
   "source": [
    "- Model Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2576e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", precision_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9be273",
   "metadata": {},
   "source": [
    "- Model Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c49ce3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", recall_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bbfaee",
   "metadata": {},
   "source": [
    "- Model F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0b27cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score:\", f1_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd188fc8",
   "metadata": {},
   "source": [
    "- Confusion matrix\n",
    "\n",
    "The result came in matrix: \n",
    "[[TN, FP],\n",
    " [FN, TP]]\n",
    "\n",
    " where:\n",
    "- TN = True Negative - Correctly predicted negative class (Prediction: No, Actual: No)\n",
    "- FP = False Positive - Incorrectly predicted positive class (Prediction: Yes, Actual: No)\n",
    "- FN = False Negative - Incorrectly predicted negative class (Prediction: No, Actual: Yes)\n",
    "- TP = True Positive - Correctly predicted positive class (Prediction: Yes, Actual: Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7c6ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2 2]\n",
      " [3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6d2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e60c00",
   "metadata": {},
   "source": [
    "MAE (Mean Absolute Error)\n",
    "- MAE is the average of the absolute differences between the predicted and actual values.\n",
    "- It is a measure of the average magnitude of the errors in a set of predictions, without considering their direction.\n",
    "- The formula for MAE is:\n",
    "    - MAE = (|y1 - y1'| + |y2 - y2'| + ... + |yn - yn'|) / n\n",
    "    - where y1, y2, ..., yn are the actual values and y1', y2', ..., yn' are the predicted values.\n",
    "    - n is the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54c85a",
   "metadata": {},
   "source": [
    "MSE (Mean Squared Error)\n",
    "- First in algorithm all value are squared. (Reason to square the values is to remove the negative sign and error of bigger values are more easy to recognise than of smaller values)\n",
    "- Then a mean of all the values is taken.\n",
    "- This is used to measure the accuracy of a regression model.\n",
    "- The lower the value the better the model.\n",
    "- The higher the value the worse the model.\n",
    "- The formula for MSE is:\n",
    "    - MSE = (1/n) * Σ(yi - ŷi)^2\n",
    "    - yi = actual value\n",
    "    - ŷi = predicted value\n",
    "    - n = number of values\n",
    "    - Σ = sum of all values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e779d0",
   "metadata": {},
   "source": [
    "RSME (Root Mean Squared Error)\n",
    "- RMSE is the square root of the average of the squared differences between predicted values and actual values.\n",
    "- RMSE is a measure of how well a model can predict a continuous outcome.\n",
    "- RMSE is always positive.\n",
    "- RMSE is in the same units as the target variable.\n",
    "- RMSE is sensitive to outliers.\n",
    "- The formula for RMSE is:\n",
    "    - RMSE = sqrt(1/n * sum((y_i - y_pred_i)^2))\n",
    "    - n = number of observations\n",
    "    - y_i = actual value\n",
    "    - y_pred_i = predicted value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86079e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = [90, 60, 80, 100]\n",
    "Y_pred = [85, 70, 70, 95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec4029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (On average off by): 7.5\n",
      "Mean Squared Error (Squared mistake value): 62.5\n",
      "Root Mean Squared Error (Final realist error): 7.905694150420948\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(Y_true, Y_pred)\n",
    "print(\"Mean Absolute Error (On average off by):\", mae)\n",
    "\n",
    "mse = mean_squared_error(Y_true, Y_pred)\n",
    "print(\"Mean Squared Error (Squared mistake value):\", mse)\n",
    "\n",
    "print(\"Root Mean Squared Error (Final realist error):\", np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
